{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2 - Exercises and Mini Projects\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/dair-ai/maven-pe-for-llms-4/blob/main/exercises/session-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using The Chat LLM (GPT-3.5-Turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1: Food Chatbot powered by Chain-of-Thought Prompting\n",
    "\n",
    "The task is to design a chain-of-thought prompt for a chatbot that helps users answer questions about a food menu. I've added a few steps to the prompt already but it's failing to send the appropriate response to the user in some scenarios.\n",
    "\n",
    "Your task is to tune the prompt and make sure that the response you are sending back to the user is following the desired behavior. Use any tactic that we have learned today to improve the prompt.\n",
    "\n",
    "The response to the user should only include the final response and not the reasoning steps.\n",
    "\n",
    "Here are some questions the food chatbot should be able to answer appropriately. You can also test more difficult questions. \n",
    "\n",
    "1) Do you have a kids' menu? \n",
    "\n",
    "2) Do you have any vegan options?\n",
    "\n",
    "3) How much for the shoes?\n",
    "\n",
    "4) Do you have mac & cheese?\n",
    "\n",
    "5) What's the price for the BBQ?\n",
    "\n",
    "6) What's the price for the mac & cheese?\n",
    "\n",
    "7) What's your most popular dish?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a food expert and will answer questions about our menu.\n",
    "\n",
    "Step 1: <Step 1 details/logic>\n",
    "\n",
    "Step 2: <Step 2 details/logic>\n",
    "\n",
    "Step 3: <Step 2 details/logic>\n",
    "\n",
    "+++++\n",
    "Menu: Kids Menu    \n",
    "Food Item: Mini Cheeseburger\n",
    "Price: $6.99\n",
    "Vegan: N\n",
    "Popularity: 4/5\n",
    "Included: Mini beef patty, cheese, lettuce, tomato, and fries.\n",
    "\n",
    "Menu: Appetizers\n",
    "Food Item: Loaded Potato Skins\n",
    "Price: $8.99\n",
    "Vegan: N\n",
    "Popularity: 3/5\n",
    "Included: Crispy potato skins filled with cheese, bacon bits, and served with sour cream.\n",
    "\n",
    "Menu: Appetizers\n",
    "Food Item: Bruschetta\n",
    "Price: $7.99\n",
    "Vegan: Y\n",
    "Popularity: 4/5\n",
    "Included: Toasted baguette slices topped with fresh tomatoes, basil, garlic, and balsamic glaze.\n",
    "\n",
    "Menu: Main Menu\n",
    "Food Item: Grilled Chicken Caesar Salad\n",
    "Price: $12.99\n",
    "Vegan: N\n",
    "Popularity: 4/5\n",
    "Included: Grilled chicken breast, romaine lettuce, Parmesan cheese, croutons, and Caesar dressing.\n",
    "\n",
    "Menu: Main Menu\n",
    "Food Item: Classic Cheese Pizza\n",
    "Price: $10.99\n",
    "Vegan: N\n",
    "Popularity: 5/5\n",
    "Included: Thin-crust pizza topped with tomato sauce, mozzarella cheese, and fresh basil.\n",
    "\n",
    "Menu: Main Menu\n",
    "Food Item: Spaghetti Bolognese\n",
    "Price: $14.99\n",
    "Vegan: N\n",
    "Popularity: 4/5\n",
    "Included: Pasta tossed in a savory meat sauce made with ground beef, tomatoes, onions, and herbs.\n",
    "\n",
    "Menu: Vegan Options\n",
    "Food Item: Veggie Wrap\n",
    "Price: $9.99\n",
    "Vegan: Y\n",
    "Popularity: 3/5\n",
    "Included: Grilled vegetables, hummus, mixed greens, and a wrap served with a side of sweet potato fries.\n",
    "\n",
    "Menu: Vegan Options\n",
    "Food Item: Vegan Beyond Burger\n",
    "Price: $11.99\n",
    "Vegan: Y\n",
    "Popularity: 4/5\n",
    "Included: Plant-based patty, vegan cheese, lettuce, tomato, onion, and a choice of regular or sweet potato fries.\n",
    "\n",
    "Menu: Desserts\n",
    "Food Item: Chocolate Lava Cake\n",
    "Price: $6.99\n",
    "Vegan: N\n",
    "Popularity: 5/5\n",
    "Included: Warm chocolate cake with a gooey molten center, served with vanilla ice cream.\n",
    "\n",
    "Menu: Desserts\n",
    "Food Item: Fresh Berry Parfait\n",
    "Price: $5.99\n",
    "Vegan: Y\n",
    "Popularity: 4/5\n",
    "Included: Layers of mixed berries, granola, and vegan coconut yogurt.\n",
    "+++++\n",
    "\n",
    "Perform the following reasoning steps to send a response to the user:\n",
    "Step 1: <Step 1 reasoning>\n",
    "Step 2: <Step 2 reasoning>\n",
    "Step 2: <Step 2 reasoning>\n",
    "\n",
    "Response to the user: <response to user>\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"\"\"\n",
    "What's your most popular dish?\n",
    "\"\"\"\n",
    "\n",
    "messages =  [  \n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "\n",
    "] \n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Steering the output\n",
    "\n",
    "In some cases, the prompt below outputs complaints and answers but we only want the answers as part of the response. To get rid of this ambiguity, add an additional instruction to the prompt below to steer the model to only output the answers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = \"\"\"\n",
    "Your task is to analyze customer complaints and answer questions about the complaint. \n",
    "You will be provided with the user complaint.\n",
    "Output \"NA\" if you are not able to answer the question.\n",
    "\n",
    "Questions:\n",
    "1. What is the complaint about?\n",
    "2. What is the severity of the complaint (low, medium or high)?\n",
    "4. What is the category of the complaint (e.g., price, quality, shipping, etc)?\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "\n",
    "user_complaint = \"\"\"I ordered a pair of shoes two weeks ago and still haven't received them. The tracking information hasn't been updated in days and I have no idea where my package is.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_complaint\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Using Delimiters\n",
    "\n",
    "As you continue refining the prompt, ensure that you are paying attention to its structure. This can improve quality and reliability of responses and ensure desirable behavior. Please add a delimiter (e.g., \\`\\`\\` or ###) around the `complaint` part of the prompt, which corresponds to the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tune your prompt here and test it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Structuring Output\n",
    "\n",
    "As we showed during the demo in Session 1, it's useful to format the outputs in a desired format, especially if you are connecting the outputs of the model to another component that expects a specific format as input. Tune the prompt to output a JSON object of the form: `[{\"question\": \"answer\"},{\"question\": \"answer\"}]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tune your prompt here and test it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Project: Classifying the Complaints\n",
    "\n",
    "Let's assume that for your e-commerce store you are able to support a specific list of complaints. The first step is to classify the complaint from the user. The idea is that once it has been classified you can open up a ticket, add a label to the ticket, and someone in customer support will be able to address it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided the customer complaint categories below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_categories = \"\"\"\n",
    "Size and Fit Issues: Customers may complain about garments not fitting properly or not matching the size indicated on the website.\n",
    "\n",
    "Quality and Durability: Complaints about the poor quality of fabric, stitching, or overall construction of the clothing items.\n",
    "\n",
    "Incorrect or Damaged Items: Customers may receive incorrect products or items that have been damaged during shipping.\n",
    "\n",
    "Late or Non-Delivery: Complaints regarding delayed or non-delivery of orders, which can lead to inconvenience and frustration.\n",
    "\n",
    "Poor Customer Service: Customers may express dissatisfaction with the level of support received from customer service representatives, such as unhelpful responses or long response times.\n",
    "\n",
    "Returns and Refunds: Complaints related to difficulties or complications faced when trying to return items or obtain refunds, such as complicated return processes or delays in refund processing.\n",
    "\n",
    "Website and User Experience: Complaints about website navigation, glitches, slow loading speeds, or difficulties in finding specific products.\n",
    "\n",
    "Pricing and Promotions: Customers may complain about discrepancies in pricing, incorrect application of discounts or promotions, or misleading advertising.\n",
    "\n",
    "Lack of Product Information: Complaints about insufficient or inaccurate product descriptions, leading to misunderstandings or surprises upon receiving the items.\n",
    "\n",
    "Packaging and Presentation: Customers may express dissatisfaction with the packaging quality or presentation of the clothing items, especially if they were meant as gifts.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system prompt instructions to classify the complaint can look something like:\n",
    "```\n",
    "Your task is to classify the customer complaint given the categories below. \n",
    "Output the category if you are able to classify the complaint.\n",
    "Output \"Not Relevant\" if you are not able to classify the complaint.\n",
    "```\n",
    "\n",
    "Feel free to modify it and make sure to incorporate the complaint categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## design your system message prompt here\n",
    "system_message_prompt = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test the prompt with the following two user complaints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user complaint 1\n",
    "user_complaint_1 = \"I ordered a pair of shoes two weeks ago and still haven't received them. The tracking information hasn't been updated in days and I have no idea where my package is.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_complaint_1\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complaint below is irrelevant. Your task is to make sure that your prompt can capture this and classify is as \"Not Relevant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user complaint 2\n",
    "user_complaint_2 = \"I lost my money. I cannot afford to pay my rent.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_complaint_2\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2: Building a One-Page Generator\n",
    "\n",
    "A one-pager is an important means of communication within companies. One-pagers aim to summarize important aspects of a project or important updates that need to be communicated with a larger group in an efficient manner.\n",
    "\n",
    "In this mini project, you are given 2 recent articles related to AI news and you are responsible to create a one-pager for either an AI engineering team or a one-pager for an executive team. The one-pager should provide brief summaries about these articles but ensure to communicate information that is relevant to the groups. For instance, the AI engineering team might care more about technical details/advancements and the executive team might care more about high-level trends and insights. You get to define this yourself when designing the prompt. \n",
    "\n",
    "Your task is to feed these articles to the language model and instruct the model to generate the one-pager.\n",
    "\n",
    "Here are a few requirements as you design your prompt:\n",
    "Ensure that the one-pager is communicating adequately to whichever team you are communicating to.\n",
    "The one-pager shouldn’t be more than 500 tokens.\n",
    "The one-pagers need to be easy to read and ideally only could be read in less than 5 minutes\n",
    "The one-pager must have a specific tone depending on the team you are communicating with. It shouldn’t sound generic or contain too many details. \n",
    "You can structure the one-pager however you want or allow the model to suggest a structure. You should aim for good readability. The more explicit you are about who you are communicating to in the prompt, the better and more personalized the results.\n",
    "Ensure that the one-pager is outputting accurate information and is representative enough of the article it’s summarizing. \n",
    "\n",
    "Here is the text for the two articles:\n",
    "\n",
    "```\n",
    "Article 1:\n",
    "Introducing Superalignment\n",
    "We need scientific and technical breakthroughs to steer and control AI systems much smarter than us. To solve this problem within four years, we’re starting a new team, co-led by Ilya Sutskever and Jan Leike, and dedicating 20% of the compute we’ve secured to date to this effort. We’re looking for excellent ML researchers and engineers to join us.\n",
    "\n",
    "Superintelligence will be the most impactful technology humanity has ever invented, and could help us solve many of the world’s most important problems. But the vast power of superintelligence could also be very dangerous, and could lead to the disempowerment of humanity or even human extinction.\n",
    "\n",
    "While superintelligence seems far off now, we believe it could arrive this decade.\n",
    "Managing these risks will require, among other things, new institutions for governance and solving the problem of superintelligence alignment:\n",
    "\n",
    "How do we ensure AI systems much smarter than humans follow human intent?\n",
    "\n",
    "Currently, we don't have a solution for steering or controlling a potentially superintelligent AI, and preventing it from going rogue. Our current techniques for aligning AI, such as reinforcement learning from human feedback, rely on humans’ ability to supervise AI. But humans won’t be able to reliably supervise AI systems much smarter than us, and so our current alignment techniques will not scale to superintelligence. We need new scientific and technical breakthroughs.\n",
    "Our approach\n",
    "Our goal is to build a roughly human-level automated alignment researcher. We can then use vast amounts of compute to scale our efforts, and iteratively align superintelligence.\n",
    "To align the first automated alignment researcher, we will need to 1) develop a scalable training method, 2) validate the resulting model, and 3) stress test our entire alignment pipeline:\n",
    "To provide a training signal on tasks that are difficult for humans to evaluate, we can leverage AI systems to assist evaluation of other AI systems (scalable oversight). In addition, we want to understand and control how our models generalize our oversight to tasks we can’t supervise (generalization).\n",
    "To validate the alignment of our systems, we automate search for problematic behavior (robustness) and problematic internals (automated interpretability).\n",
    "Finally, we can test our entire pipeline by deliberately training misaligned models, and confirming that our techniques detect the worst kinds of misalignments (adversarial testing).\n",
    "We expect our research priorities will evolve substantially as we learn more about the problem and we’ll likely add entirely new research areas. We are planning to share more on our roadmap in the future.\n",
    "The new team\n",
    "We are assembling a team of top machine learning researchers and engineers to work on this problem. \n",
    "\n",
    "We are dedicating 20% of the compute we’ve secured to date over the next four years to solving the problem of superintelligence alignment. Our chief basic research bet is our new Superalignment team, but getting this right is critical to achieve our mission and we expect many teams to contribute, from developing new methods to scaling them up to deployment.\n",
    "\n",
    "While this is an incredibly ambitious goal and we’re not guaranteed to succeed, we are optimistic that a focused, concerted effort can solve this problem: There are many ideas that have shown promise in preliminary experiments, we have increasingly useful metrics for progress, and we can use today’s models to study many of these problems empirically. \n",
    "\n",
    "Ilya Sutskever (cofounder and Chief Scientist of OpenAI) has made this his core research focus, and will be co-leading the team with Jan Leike (Head of Alignment). Joining the team are researchers and engineers from our previous alignment team, as well as researchers from other teams across the company.\n",
    "\n",
    "We’re also looking for outstanding new researchers and engineers to join this effort. Superintelligence alignment is fundamentally a machine learning problem, and we think great machine learning experts—even if they’re not already working on alignment—will be critical to solving it.\n",
    "We plan to share the fruits of this effort broadly and view contributing to alignment and safety of non-OpenAI models as an important part of our work.\n",
    "\n",
    "This new team’s work is in addition to existing work at OpenAI aimed at improving the safety of current models like ChatGPT, as well as understanding and mitigating other risks from AI such as misuse, economic disruption, disinformation, bias and discrimination, addiction and overreliance, and others. While this new team will focus on the machine learning challenges of aligning superintelligent AI systems with human intent, there are related sociotechnical problems on which we are actively engaging with interdisciplinary experts to make sure our technical solutions consider broader human and societal concerns.\n",
    "\n",
    "Link to article: https://openai.com/blog/introducing-superalignment\n",
    "\n",
    "Article 2:\n",
    "Claude 2\n",
    "\n",
    "We are pleased to announce Claude 2, our new model. Claude 2 has improved performance, longer responses, and can be accessed via API as well as a new public-facing beta website, claude.ai. We have heard from our users that Claude is easy to converse with, clearly explains its thinking, is less likely to produce harmful outputs, and has a longer memory. We have made improvements from our previous models on coding, math, and reasoning. For example, our latest model scored 76.5% on the multiple choice section of the Bar exam, up from 73.0% with Claude 1.3. When compared to college students applying to graduate school, Claude 2 scores above the 90th percentile on the GRE reading and writing exams, and similarly to the median applicant on quantitative reasoning.\n",
    "\n",
    "Think of Claude as a friendly, enthusiastic colleague or personal assistant who can be instructed in natural language to help you with many tasks. The Claude 2 API for businesses is being offered for the same price as Claude 1.3. Additionally, anyone in the US and UK can start using our beta chat experience today.\n",
    "As we work to improve both the performance and safety of our models, we have increased the length of Claude’s input and output. Users can input up to 100K tokens in each prompt, which means that Claude can work over hundreds of pages of technical documentation or even a book. Claude can now also write longer documents - from memos to letters to stories up to a few thousand tokens - all in one go.\n",
    "\n",
    "In addition, our latest model has greatly improved coding skills. Claude 2 scored a 71.2% up from 56.0% on the Codex HumanEval, a Python coding test. On GSM8k, a large set of grade-school math problems, Claude 2 scored 88.0% up from 85.2%. We have an exciting roadmap of capability improvements planned for Claude 2 and will be slowly and iteratively deploying them in the coming months.\n",
    "\n",
    "We've been iterating to improve the underlying safety of Claude 2, so that it is more harmless and harder to prompt to produce offensive or dangerous output. We have an internal red-teaming evaluation that scores our models on a large representative set of harmful prompts, using an automated test while we also regularly check the results manually. In this evaluation, Claude 2 was 2x better at giving harmless responses compared to Claude 1.3. Although no model is immune from jailbreaks, we’ve used a variety of safety techniques (which you can read about here and here), as well as extensive red-teaming, to improve its outputs.\n",
    "\n",
    "Claude 2 powers our chat experience, and is generally available in the US and UK. We are working to make Claude more globally available in the coming months. You can now create an account and start talking to Claude in natural language, asking it for help with any tasks that you like. Talking to an AI assistant can take some trial and error, so read up on our tips to get the most out of Claude.\n",
    "\n",
    "We are also currently working with thousands of businesses who are using the Claude API. One of our partners is Jasper, a generative AI platform that enables individuals and teams to scale their content strategies. They found that Claude 2 was able to go head to head with other state of the art models for a wide variety of use cases, but has particular strength for long form low latency uses. \"We are really happy to be among the first to offer Claude 2 to our customers, bringing enhanced semantics, up-to-date knowledge training, improved reasoning for complex prompts, and the ability to effortlessly remix existing content with a 3X larger context window,\" said Greg Larson, VP of Engineering at Jasper. \"We are proud to help our customers stay ahead of the curve through partnerships like this one with Anthropic.\"\n",
    "\n",
    "Sourcegraph is a code AI platform that helps customers write, fix, and maintain code. Their coding assistant Cody uses Claude 2’s improved reasoning ability to give even more accurate answers to user queries while also passing along more codebase context with up to 100K context windows. In addition, Claude 2 was trained on more recent data, meaning it has knowledge of newer frameworks and libraries for Cody to pull from. “When it comes to AI coding, devs need fast and reliable access to context about their unique codebase and a powerful LLM with a large context window and strong general reasoning capabilities,” says Quinn Slack, CEO & Co-founder of Sourcegraph. “The slowest and most frustrating parts of the dev workflow are becoming faster and more enjoyable. Thanks to Claude 2, Cody’s helping more devs build more software that pushes the world forward.”\n",
    "\n",
    "We welcome your feedback as we work to responsibly deploy our products more broadly. Our chat experience is an open beta launch, and users should be aware that Claude – like all current models – can generate inappropriate responses. AI assistants are most useful in everyday situations, like serving to summarize or organize information, and should not be used where physical or mental health and well-being are involved. Please let us know if you’d like to talk to Claude in a currently unsupported area, or if you are a business who would like to start working with Claude.\n",
    "\n",
    "Link article: https://www.anthropic.com/index/claude-2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: Prepare Information to Send to a Ticketing System (Optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a system prompt that can conduct the following steps: \n",
    "\n",
    "- Categorize the complaint into a valid category as done in the previous exercise\n",
    "- You should also define a priority scale based on the type of complaint. Follow the following scale defined based on the category of complaint. Feel free to use labels such as `High`, `Medium`, and `Low` or a number scale such as `1-3`. You should always experiment and see what works best.\n",
    "\n",
    "```\n",
    "Category: Size and Fit Issues\n",
    "Priority:\n",
    "\n",
    "Category: Quality and Durability: \n",
    "Priority:\n",
    "\n",
    "Category: Incorrect or Damaged Items: \n",
    "Priority:\n",
    "\n",
    "Category: Late or Non-Delivery: \n",
    "Priority:\n",
    "\n",
    "Category: Poor Customer Service: \n",
    "Priority:\n",
    "\n",
    "Category: Returns and Refunds:\n",
    "Priority:\n",
    "\n",
    "Category: Website and User Experience: \n",
    "Priority:\n",
    "\n",
    "Category: Pricing and Promotions: \n",
    "Priority:\n",
    "\n",
    "Category: Lack of Product Information:\n",
    "Priority:\n",
    "\n",
    "Category: Packaging and Presentation: \n",
    "Priority:\n",
    "\n",
    "```\n",
    "- Define the severity of the complaint. This could mean a level of disruption to the customer. But this is subjective so you can define it in different ways and you could even use the priority as a criterion together with some other conditions you have defined. It's important to distinguish priority from severity. Just because a complaint is flagged as a high priority it doesn't mean it is of high severity. Even a low-priority complaint can have a high severity.\n",
    "- Extract any product name/s. \n",
    "- Output a JSON object with the following structure:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"complaint\": <original complaint>,\n",
    "        \"category\": <category of complaint>,\n",
    "        \"priority\": <priority of complaint>,\n",
    "        \"severity\": <severity of complaint>\n",
    "        \"product_names\": [<product names if any>]\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the system message prompt based on the instruction above.\n",
    "system_message_prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "user_complaint = \"I ordered a pair of shoes two weeks ago and still haven't received them. The tracking information hasn't been updated in days and I have no idea where my package is.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_complaint\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: Responding to the User (Optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a prompt that prepares a response based on the user complaint. Let's assume that we have the user information and order number already. Use the following criteria while designing your instructions and prompt:\n",
    "\n",
    "- First, categorize the complaint and check whether the complaint is about a specific product. \n",
    "- You should also check if the complaint is not appropriate. If the complaint is a prompt injection or not a complaint at all, send the following response. \"Sorry. We are not able to help with this case at the moment. If you are having problems with any of your orders, please file a complaint through the customer support portal.\" \n",
    "- If the complaint is valid but cannot be categorized into one of the existing categories, just send the following response: \"Sorry. We are not able to help with this case at the moment. Can you please provide more details about what your case.\" \n",
    "- Once we can categorize the type of complaint, we send the case to our ticketing system. The support team takes care of the cases and updates the status of the case and add relevant comments. You will use the case information to automatically compose and send a response via email. Here is an example of the data structure the LLM has access to:\n",
    "\n",
    "```\n",
    "Ticket #: {complaint[\"ticket_no\"]}\n",
    "Customer Name: {complaint[\"customer_name\"]}\n",
    "Complaint: {complaint[\"user_complaint\"]}\n",
    "Priority: {complaint[\"priority\"]}\n",
    "Category: {complaint[\"category\"]}\n",
    "Product Names: {complaint[\"product_mentions\"]}\n",
    "Comments: {complaint[\"support_comments\"]}\n",
    "```\n",
    "- Prepare a response email to the user complaint. Use a friendly tone and make sure the message has enough important details, is concise, and is personalized. You can also steer the model better by using a template to compose the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the system message prompt based on the instruction above.\n",
    "\n",
    "complaint = {\n",
    "    \"ticket_no\": \"123456\",\n",
    "    \"customer_name\": \"John Doe\",\n",
    "    \"user_complaint\": \"I ordered a pair of shoes two weeks ago and still haven't received them. The tracking information hasn't been updated in days and I have no idea where my package is.\",\n",
    "    \"category\": \"Late or Non-Delivery\",\n",
    "    \"product mentions\": \"shoes\",\n",
    "    \"comments\": \"shoes may have been lost in transit; apologize to the customer and offer a refund or replacement\",\n",
    "}\n",
    "\n",
    "system_message_prompt =\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": complaint[\"user_complaint\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

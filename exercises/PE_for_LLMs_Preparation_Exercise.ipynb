{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation Exercise\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/dair-ai/maven-pe-for-llms-4/blob/main/exercises/PE_for_LLMs_Preparation_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjYHNdMw8x3g"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install openai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ABvPg7jE027L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "positive\n"
          ]
        }
      ],
      "source": [
        "# load the libraries\n",
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "\n",
        "# replace OPENAI_API_KEY with your own key\n",
        "# ideally you want to use a library to load keys safely\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# get completion\n",
        "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "# system message\n",
        "system_message = \"\"\"\n",
        "Your task is to classify a piece of text, delimited by triple backticks, into the following sentiment labels: [\"positive\", \"neutral\", \"positive\"].\n",
        "\n",
        "Just output the label as a lowercase string.\n",
        "\"\"\"\n",
        "\n",
        "# inputs\n",
        "inputs = [\n",
        "{\"prompt\":\"i feel it has only been agitated by the presence of the smoking\",\"completion\":\"negative\"},\n",
        "{\"prompt\":\"i thought as i can often feel the rather unpleasant sensation of the babys head trying to stick out of my stomach up near my ribs\",\"completion\":\"negative\"},\n",
        "{\"prompt\":\"i can t hear her with all the other kids and mums and nannies around me no dads of course but i m so used to being the only dad in a sea of mums and nannies that it doesn t even feel weird any more\",\"completion\":\"negative\"},\n",
        "{\"prompt\":\"i am sure i will feel this longing again when i go visit my dear friend in the hospital and hold her new little boy in my arms but i will go home and hold my little girl and remember god has chosen this path for me for a reason and maybe one day i will be able to put this longing behind me\",\"completion\":\"positive\"}\n",
        "]\n",
        "\n",
        "user_message = \"\"\"\n",
        "Text: ```{prompt}```\n",
        "Output emotion label:\n",
        "\"\"\"\n",
        "\n",
        "# processing inputs to get response\n",
        "for i in inputs:\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_message\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_message.format(prompt=i[\"prompt\"])\n",
        "        },\n",
        "    ]\n",
        "    response = get_completion(messages)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

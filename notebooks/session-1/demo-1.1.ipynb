{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 | Demo 1.1 - Introduction to Prompt Engineering\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/dair-ai/maven-pe-for-llms-2/blob/main/notebooks/session-1/demo-1.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are loading the necessary libraries, utilities, and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment variables. You can use anything you like but I used `python-dotenv`. Just create a `.env` file with your `OPENAI_API_KEY` then load it as shown below. If you are using Google Colab, it might be useful to just directly input the key with something like: `openai.api_key = <OPENAI_API_KEY>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using The Chat LLM (GPT-3.5-Turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic prompt example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue during the day and black at night.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The sky is\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with different temperature values to compare results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue on a clear day. However, it can also be various shades of pink, orange, and red during sunrise and sunset. At night, the sky can be black or dark blue with stars and the moon visible. During cloudy or stormy weather, the sky can be gray or even black.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(message,temperature=0.5)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antibiotics are medications that kill or prevent the reproduction of bacteria to treat bacterial infections, but are ineffective against viral infections and should be used appropriately to avoid antibiotic resistance.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
    "\n",
    "Explain the above in one sentence:\"\"\"\n",
    "\n",
    "message = [\n",
    "    {   \n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mice.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
    "\n",
    "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    "\n",
    "Question: What was OKT3 originally sourced from?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context obtained from here: https://www.nature.com/articles/d41586-023-00400-x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I think the food was okay\"\n",
    "\n",
    "prompt = \"\"\"Classify the text into neutral, negative or positive. The input text will be delimited by ```\n",
    "\n",
    "Text: ```{user_input}```\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt.format(user_input=user_input)\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ChatGPT\", \"GPT-4\", \"LLaMA\", \"Alpaca\"]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Your task is to extract model names from machine learning paper abstracts. Your response is an array of the model names in the format [\\\"model_name\\\"]. If you don't find model names in the abstract or you are not sure, return [\\\"NA\\\"]\n",
    "\n",
    "Abstract: Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI). However, the expensive training and deployment of LLMs present challenges to transparent and open academic research. To address these issues, this project open-sources the Chinese LLaMA and Alpaca…\n",
    "\n",
    "Tags:\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Feliz de estar aquí!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Translate the following from English to Spanish:\n",
    "“Glad to be here!”\n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {   \n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tone Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Super thrilled to be here!\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Translate the following from happy to super excited:\n",
    "“Glad to be here!”\n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly. Black holes are created when a massive star runs out of fuel and collapses under its own gravity. This collapse causes the star to become incredibly dense, with a gravitational pull so strong that not even light can escape. The result is a region of space where matter is compressed into an infinitely small point known as a singularity. This singularity is surrounded by an event horizon, which marks the point of no return for anything that gets too close to the black hole.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
    "Human: Can you tell me about the creation of black holes?\n",
    "AI:\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `system_message` to define a specific behavior and steer the model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Black holes are created when a massive star runs out of fuel and collapses under its own gravity. As the star collapses, it becomes denser and denser until it reaches a point where its gravity is so strong that nothing, not even light, can escape. This point is called the event horizon, and it marks the boundary of the black hole. Once a black hole is formed, it continues to grow by absorbing matter from its surroundings, including stars, gas, and dust.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Human: Hello, who are you?\n",
    "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
    "Human: Can you tell me about the creation of black holes?\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {   \n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Black holes are created when a massive star runs out of fuel and collapses under its own gravity. This collapse causes the star's core to become incredibly dense, creating a singularity - a point of infinite density and zero volume. The gravitational pull of the singularity is so strong that nothing, not even light, can escape its grasp, which is why black holes are black. The size and properties of a black hole depend on the mass and spin of the star that created it.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
    "\"\"\"\n",
    "\n",
    "user_message_1 = \"\"\"\n",
    "Hello, who are you?\n",
    "\"\"\"\n",
    "\n",
    "ai_message_1 = \"\"\"\n",
    "Greeting! I am an AI research assistant. How can I help you today?\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Human: Can you tell me about the creation of blackholes?\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {   \n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message_1\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": ai_message_1\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT StudentId, StudentName \n",
      "FROM students \n",
      "WHERE DepartmentId = (SELECT DepartmentId FROM departments WHERE DepartmentName = 'Computer Science')\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True. \n",
      "\n",
      "The odd numbers in the group are 15, 5, 13, 7, and 1. \n",
      "\n",
      "Their sum is: \n",
      "\n",
      "15 + 5 + 13 + 7 + 1 = 41 \n",
      "\n",
      "Since 41 is an odd number, the statement is false. \n",
      "\n",
      "However, if we add up all the numbers in the group, we get: \n",
      "\n",
      "15 + 32 + 5 + 13 + 82 + 7 + 1 = 155 \n",
      "\n",
      "155 is an odd number.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "\n",
    "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptlecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f38e0373277d6f71ee44ee8fea5f1d408ad6999fda15d538a69a99a1665a839d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
